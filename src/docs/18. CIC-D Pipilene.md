# Cloud Explorer Project Documentation

This document provides an overview of the Cloud Explorer project, its architecture, development setup, and CI/CD pipeline using Google Cloud Platform (GCP).

## Table of Contents

1. [Project Overview](#project-overview)
2. [System Architecture](#system-architecture)
    * [Application Architecture](#application-architecture)
    * [Cloud Architecture](#cloud-architecture)
3. [Development Setup](#development-setup)
    * [Prerequisites](#prerequisites)
    * [Installation](#installation)
    * [Running Locally](#running-locally)
    * [Docker Compose](#docker-compose)
    * [Environment Variables](#environment-variables)
4. [CI/CD Pipeline with Google Cloud Build](#cicd-pipeline-with-google-cloud-build)
    * [Components](#components)
    * [Pipeline Steps](#pipeline-steps)
    * [GCR Push](#gcr-push)
    * [Cloud Run Deployment](#cloud-run-deployment)
    * [Cloud Build Trigger](#cloud-build-trigger)
5. [File Structure](#file-structure)
    * [Dockerfile.dev](#dockerfiledev)
    * [backend/Dockerfile](#backenddockerfile)
    * [docker-compose.yml](#docker-composeyml)
    * [backend/server.js](#backendserverjs)
    * [package.json](#packagejson)
    * [cloudbuild.yaml](#cloudbuildyaml)
6. [Backend API Endpoints](#backend-api-endpoints)
7. [Contributing](#contributing)
8. [License](#license)

## Project Overview

Cloud Explorer is a mobile application built using React Native that helps users learn Google Cloud Platform (GCP) concepts through interactive informatics, engaging quizzes, and exams.

## System Architecture

### Application Architecture

* **Frontend:** React Native (JavaScript/TypeScript) for cross-platform mobile application development (iOS and Android).
* **Backend:** Node.js with Express.js for handling API requests.
* **Database:** Firestore (Firebase) for a real-time, NoSQL database.
* **Libraries:** Firebase and GoogleApis, React-navigation, Axios, Victory-Native
* **State Management:** Redux (can be implemented) for efficient state management.
* **Authentication:** Firebase Authentication for secure user authentication.
* **API Interaction:** Axios for HTTP requests to interact with the backend.
* **UI Library:** react-native-paper, react-native-svg for UI components.
* **Data Visualization:** Victory-Native for data visualization.

![Application Architecture](../assets/images/CloudExplocer-App-Architecture.svg)

### Cloud Architecture

* **Compute:** Google Cloud Run for deploying and managing containerized backend applications.
* **Database:** Firestore for storing application data.
* **Authentication:** Firebase Authentication for secure user authentication.
* **CI/CD:** Google Cloud Build for continuous integration and deployment.
* **Container Registry:** Google Container Registry (GCR) for storing Docker images.

![Cloud Architecture](../assets/images/CloudExplorer-Cloud-Architecture.svg)

**Benefits of the Cloud Architecture:**

* **Scalability:** Cloud Run provides automatic scaling for the backend.
* **Performance:** Firestore offers real-time data synchronization and fast data retrieval.
* **Security:** Firebase Authentication and GCP's built-in security features.
* **Reliability:** High availability and fault tolerance provided by GCP.
* **Ease of Development:** Managed services reduce operational overhead.
* **Cost Efficiency:** Pay-as-you-go pricing for cloud resources.
* **AI Integration:** Integration of AI frameworks (TensorFlow, Hugging Face, OpenAI) for advanced features.

## Development Setup

### Prerequisites

* Node.js (version 18 recommended) and npm
* React Native CLI (`npm install -g react-native-cli`)
* Docker
* Google Cloud SDK installed and configured (`gcloud auth login`)
* Firebase project set up

### Installation

1. Clone the repository:

    ```bash
    git clone https://github.com/220296006/CloudExplorer.git
    cd CloudExplorer
    ```

2. Install the dependencies:

   ```bash
   npm install
   ```

4. Set up Firebase:

* Create a Firebase project and enable Authentication and Firestore.
* Download the google-services.json file and place it in the android/app directory.
* Download the GoogleService-Info.plist file and place it in the ios directory.
* Download the serviceAccountKey.json file and place it in the backend directory.

### Running Locally

1. Start the React Native development server:

   ```bash
   npx react-native start
   ```

2. Run the app on an emulator or physical device:

   ```bash
    npx react-native run-android
   ```

### Docker Compose

1. To run the project using Docker Compose:

    ```bash
    npx react-native start
    ```

This will start the frontend dev container and backend container, and redis database.

### Environment Variables

* Create a **.env** file in the project root to store environment variables for the frontend.
* Create a **.env** file in the backend/ directory for the backend variables.
  * **FIREBASE_PROJECT_ID**
  * **FIREBASE_PRIVATE_KEY**
  * **FIREBASE_CLIENT_EMAIL**
  * **FIREBASE_SERVICE_ACCOUNT_PATH**: should be set to ./serviceAccountKey.json.
* Add **REACT_NATIVE_PACKAGER_HOSTNAME=localhost, ADB_IP=host.docker.internal** to the file.

### CI/CD Pipeline with Google Cloud Build

This project uses Google Cloud Build to automate the CI/CD pipeline for both the frontend and backend components.

#### Components

* **cloudbuild.yaml**: Defines the build steps, including building Docker images, pushing them to Google Container Registry (GCR), and deploying the backend to Cloud Run.
* **Dockerfile.dev**: Used to build the frontend development image.
* **backend/Dockerfile**: Used to build the production-ready backend image.
* **Google Container Registry (GCR)**: Stores the built Docker images.
* **Google Cloud Run**: Hosts the deployed backend service.
* **Google Cloud Build Triggers**: Automates the pipeline on code push to the repository.

### Pipeline Steps

1. **Build Frontend Dev Image**:

   * Uses **Dockerfile.dev** to build a development image.
   * Tags the image with the project ID and commit SHA: **gcr.io/cloud-explorer-c3d98/cloud-explorer-frontend-dev:$COMMIT_SHA**
   * Pushes the image to GCR.

2. **Build Backend Prod Image**:

   * Uses **backend/Dockerfile** to build a production image.
   * Tags the image with the project ID and commit SHA: **gcr.io/cloud-explorer-c3d98/cloud-explorer-backend-prod:$COMMIT_SHA**
   * Pushes the image to GCR.

3. **Deploy Backend to Cloud Run**:

   * Uses **gcloud run deploy** to deploy the backend image to Cloud Run.
   * Configures Cloud Run to run in the **us-central1 region**.
   * Allows unauthenticated access (can be changed based on needs).

### GCR Push

* The pipeline builds and pushes both the frontend development and backend production images to GCR.0
* Images are tagged with the project ID and the commit SHA to track versions:
  * **gcr.io/cloud-explorer-c3d98/cloud-explorer-frontend-dev:$COMMIT_SHA**
  * **gcr.io/cloud-explorer-c3d98/cloud-explorer-backend-prod:$COMMIT_SHA**

### Cloud Run Deployment

* The backend is deployed to Google Cloud Run, providing a scalable and managed environment for the application.

* The command used for deployment is:
  
   ```bash
    gcloud run deploy cloud-explorer-backend --image gcr.io/$PROJECT_ID/cloud-explorer-backend-prod:$COMMIT_SHA --region us-central1 --platform managed --allow-unauthenticated
   ```

### Cloud Build Trigger

1. Go to **Cloud Build** in your GCP console.
2. Click **Triggers**.
3. Click **Create Trigger**.
4. **Name**: Give your trigger a name (e.g., "cloud-explorer-trigger").
5. **Region**: choose the correct region.
6. **Event**: Select "Push to a branch".
7. **Source**: Choose your repository and branch (e.g., **main** or **develop**).
8. **Configuration**: Select "Cloud Build configuration file" and specify the location as **cloudbuild.yaml** in the root of your repository.
9. Click on **Save**.

## File Structure

**Dockerfile.dev**

``` bash
# Dockerfile.dev
FROM node:18-slim

# Install essential tools
RUN apt-get update && apt-get install -y \
    git \
    curl \
    python3 \
    make \
    g++ \
    && rm -rf /var/lib/apt/lists/*

# Create a non-root user
RUN useradd -m appuser

# Set the working directory
WORKDIR /app

# Copy dependency files only
COPY package*.json ./

# Change ownership of these files to appuser
RUN chown -R appuser:appuser /app

# Switch to the non-root user for installing dependencies
USER appuser

# Install dependencies using npm
RUN npm install --no-bin-links --cache /tmp/.npm

# --- Stage 2: Copy Application Code ---

# Switch back to root to copy the rest of the files
USER root

# Copy the remaining application source code
COPY . .

# Ensure all files are owned by appuser
RUN chown -R appuser:appuser /app

# Switch back to the non-root user for running the app
USER appuser

# Expose the necessary ports
EXPOSE 19000 19001 19002 8081 8097

# Start the application
CMD ["npm", "run", "start"]
```

**backend/Dockerfile**

```bash
# backend/Dockerfile
FROM node:18-slim

# Set the working directory
WORKDIR /app

# Copy dependency files
COPY backend/package*.json ./

# Install dependencies
RUN npm install --production

# Copy the rest of the application code
COPY backend/ .

# Expose the port the app runs on
EXPOSE 5000

# Define the command to run the app
CMD ["node", "server.js"]

```
**docker-compose.yml**

```bash
# docker-compose.yml
services:
  # Frontend Development
  frontend-dev:
    build:
      context: .
      dockerfile: Dockerfile.dev
    devices:
      - "/dev/kvm:/dev/kvm"
    container_name: cloud-explorer-frontend-dev
    env_file: .env
    volumes:
      - .:/app
      - /app/node_modules
    ports:
      - "8081:8081"
      - "19000:19000"
      - "19001:19001"
      - "19002:19002"
      - "8097:8097"
    command: npm run start
   # Backend Service
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: cloud-explorer-backend
    ports:
      - "5000:5000"
    env_file:
      - ./backend/.env
    volumes:
      - ./backend:/app
    depends_on:
      - redis
# Redis for caching
  redis:
    image: redis:alpine
    container_name: cloud-explorer-redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data

volumes:
  redis_data:

```

**backend/server.js**

```bash
// backend/server.js
const express = require('express');
const cors = require('cors');
const { google } = require('googleapis');
const admin = require('firebase-admin');
const dotenv = require('dotenv');
const path = require('path');
const morgan = require('morgan'); // For logging HTTP requests

dotenv.config({ path: path.resolve(__dirname, '..', '.env') });

const app = express();
app.use(cors({ origin: '*' })); // Allow all origins (for development)
app.use(express.json());
app.use(morgan('dev')); // Add request logging

// Validate credentials path
const credentialsPath = process.env.FIREBASE_SERVICE_ACCOUNT_PATH;
if (!credentialsPath) {
  throw new Error('FIREBASE_SERVICE_ACCOUNT_PATH is not defined in .env');
}

// Resolve the credentials path relative to the backend directory
const absoluteCredentialsPath = path.resolve(__dirname, credentialsPath);
console.log('Loading credentials from:', absoluteCredentialsPath);
const credentials = require(absoluteCredentialsPath);

// Initialize Firebase Admin SDK
admin.initializeApp({ credential: admin.credential.cert(credentials) });

const db = admin.firestore();

const SCOPES = ['https://www.googleapis.com/auth/documents', 'https://www.googleapis.com/auth/drive'];

// Cache auth client to avoid recreating for each request
let authClient = null;
async function authenticateGoogleDocs() {
  if (authClient) {return authClient;}

  const auth = new google.auth.GoogleAuth({
    credentials,
    scopes: SCOPES,
  });
  authClient = await auth.getClient();
  return authClient;
}

// Error handler middleware
const errorHandler = (err, req, res, next) => {
  console.error('Error:', err.message);
  res.status(500).json({
    error: err.message,
    stack: process.env.NODE_ENV === 'development' ? err.stack : undefined,
  });
};

// Create a Google Doc and save to Firestore
app.post('/create-doc', async (req, res, next) => {
  try {
    const { moduleId, title, content = 'No content provided' } = req.body;
    const auth = await authenticateGoogleDocs();
    const docs = google.docs({ version: 'v1', auth });

    const document = await docs.documents.create({ requestBody: { title } });
    const documentId = document.data.documentId;

    if (!documentId || typeof documentId !== 'string' || documentId.trim() === '') {
      throw new Error('No documentId returned');
    }

    console.log('BatchUpdate params:', { documentId, content }); // Debug log
    await docs.documents.batchUpdate({
      documentId,
      requestBody: {
        requests: [{ insertText: { location: { index: 1 }, text: content } }],
      },
    });

    const docUrl = `https://docs.google.com/document/d/${documentId}/edit`;

    // Save to Firestore using provided moduleId
    if (moduleId) {
      await db.collection('modules').doc(moduleId).set({ content: docUrl }, { merge: true });
    } else if (req.body.examId) {
      await db.collection('exams').doc(req.body.examId).set({ content: docUrl }, { merge: true });
    } else {
      throw new Error('Either moduleId or examId is required');
    }

    res.json({ documentId, docUrl });
  } catch (error) {
    next(error); // Pass to error handler
  }
});

// Get Google Doc content with better error handling
app.get('/get-doc-content/:docId', async (req, res, next) => {
  try {
    const { docId } = req.params;

    if (!docId || typeof docId !== 'string' || docId.trim() === '') {
      return res.status(400).json({ error: 'Invalid document ID' });
    }

    const auth = await authenticateGoogleDocs();
    const docs = google.docs({ version: 'v1', auth });

    const response = await docs.documents.get({ documentId: docId });

    if (!response.data || !response.data.body) {
      return res.status(404).json({ error: 'Document content not found' });
    }

    res.json(response.data.body?.content || []);
  } catch (error) {
    // Check for specific error types
    if (error.code === 404 || (error.response && error.response.status === 404)) {
      return res.status(404).json({ error: 'Document not found' });
    }
    if (error.code === 403 || (error.response &&

```
## Push and Pull Images to Registry

```bash
#!/bin/bash

# Ensure the script exits if any command fails
set -e

# --- Configuration ---
# You need to change these to match your setup
PROJECT_ID="your-gcp-project-id" # Replace with your GCP Project ID
FRONTEND_IMAGE_NAME="cloud-explorer-frontend-dev"
BACKEND_IMAGE_NAME="cloud-explorer-backend-prod"
REGION="us-central1" #Change if necessary
COMMIT_SHA=$(git rev-parse --short HEAD) # Gets the current commit's short hash

# --- Functions ---
log() {
  echo "$(date '+%Y-%m-%d %H:%M:%S') - $*"
}

# --- Script Start ---
log "Starting Cloud Explorer deployment script..."

# --- Authenticate with Google Cloud ---
log "Authenticating with Google Cloud..."
gcloud auth login
gcloud auth configure-docker

# --- Build and Push Frontend Image ---
log "Building and pushing Frontend Docker image..."
docker build -f Dockerfile.dev -t "gcr.io/${PROJECT_ID}/${FRONTEND_IMAGE_NAME}:${COMMIT_SHA}" .
docker push "gcr.io/${PROJECT_ID}/${FRONTEND_IMAGE_NAME}:${COMMIT_SHA}"
log "Frontend image pushed to gcr.io/${PROJECT_ID}/${FRONTEND_IMAGE_NAME}:${COMMIT_SHA}"

# --- Build and Push Backend Image ---
log "Building and pushing Backend Docker image..."
docker build -f backend/Dockerfile -t "gcr.io/${PROJECT_ID}/${BACKEND_IMAGE_NAME}:${COMMIT_SHA}" backend/
docker push "gcr.io/${PROJECT_ID}/${BACKEND_IMAGE_NAME}:${COMMIT_SHA}"
log "Backend image pushed to gcr.io/${PROJECT_ID}/${BACKEND_IMAGE_NAME}:${COMMIT_SHA}"

# --- Deploy Backend to Cloud Run ---
log "Deploying Backend to Cloud Run..."
gcloud run deploy cloud-explorer-backend \
  --image "gcr.io/${PROJECT_ID}/${BACKEND_IMAGE_NAME}:${COMMIT_SHA}" \
  --region "${REGION}" \
  --platform managed \
  --allow-unauthenticated \
  --project "${PROJECT_ID}"
log "Backend deployed to Cloud Run."

log "Deployment script finished successfully."

```